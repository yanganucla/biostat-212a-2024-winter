---
title: "Biostat 212A Homework 3"
subtitle: "Due Feb 20, 2024 @ 11:59PM"
author: "Yang An and UID:106332601"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## ISL Exercise 5.4.2 (10pts)
2. We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of n observations.
(a) What is the probability that the first bootstrap observation is not the jth observation from the original sample? 

The probability that the first bootstrap observation is not the jth observation from the original sample is 1 - 1/n. This is because the probability of the first bootstrap observation being the jth observation from the original sample is 1/n. Therefore, the probability that the first bootstrap observation is not the jth observation from the original sample is 1 - 1/n.


(b) What is the probability that the second bootstrap observation is not the jth observation from the original sample?

The probability that the second bootstrap observation is not the jth observation from the original sample is 1 - 1/n. This is because the probability of the second bootstrap observation being the jth observation from the original sample is 1/n. Therefore, the probability that the second bootstrap observation is not the jth observation from the original sample is 1 - 1/n.
(c) Argue that the probability that the jth observation is not in the bootstrap sample is (1 − 1/n)^n.

The probability that the jth observation is not in the bootstrap sample is (1 − 1/n)^n. This is because the probability that the first bootstrap observation is not the jth observation from the original sample is 1 - 1/n. The probability that the second bootstrap observation is not the jth observation from the original sample is 1 - 1/n. Therefore, the probability that the jth observation is not in the bootstrap sample is (1 − 1/n)^n.

(d) When n = 5, what is the probability that the jth observation is in the bootstrap sample?

When n = 5, the probability that the jth observation is in the bootstrap sample is 1-(1 − 1/5)^5 = 0.67232.

(e) When n = 100, what is the probability that the jth observation is in the bootstrap sample?

When n = 100, the probability that the jth observation is in the bootstrap sample is 1-(1 − 1/100)^100 = 0.6339676587267709.

(f) When n = 10, 000, what is the probability that the jth observa- tion is in the bootstrap sample?

When n = 10, 000, the probability that the jth observation is in the bootstrap sample is 1-(1 − 1/10,000)^10,000 = 0.6321.

(g) Create a plot that displays, for each integer value of n from 1 to 100,000, the probability that the jth observation is in the bootstrap sample. Comment on what you observe.

```{r}
library(ggplot2)
boot1 <- data.frame(n = 1:100000)
boot1$prob <- 1 - (1 - 1/boot1$n)^boot1$n
ggplot(data = boot1, aes(x = n, y = prob)) +
  geom_line() +
  labs(title = "Probability that the jth observation is in the bootstrap sample",
       x = "n",
       y = "Probability") +
  theme_bw() +
  theme(text = element_text(size = 8))

```
The plot shows that the probability that the jth observation is in the bootstrap sample decreases as n increases. The probability that the jth observation is in the bootstrap sample is 1 when n = 1, and it decreases to 0.6321 when n = 10,000. 

(h) We will now investigate numerically the probability that a boot- strap sample of size n = 100 contains the jth observation. Here j = 4. We repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample.
Comment on the results obtained.

```{r}
set.seed(1)
boot2 <- rep(0, 10000)
for (i in 1:10000) {
 boot2[i] <- sum(sample(1:100, replace = TRUE) %in% 4) > 0
}
mean(boot2)

```
The probability that a bootstrap sample of size n = 100 contains the jth observation is 0.6417. This is close to the probability that the jth observation is in the bootstrap sample when n = 100, which is 0.6339676587267709.


## ISL Exercise 5.4.9 (20pts)
9. We will now consider the Boston housing data set, from the ISLR2 library.
(a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate μˆ.
```{r}
library(ISLR2)
mean.fn <- function(data, index) {
   X <- data$medv[index]
   medvmean = mean(X)
   return(medvmean)
}
dim(Boston)
mean.fn(Boston, 1:506)
```

The estimate for the population mean of medv is 22.53281.

(b) Provide an estimate of the standard error of μˆ. Interpret this result.
Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.
```{r}
se.fn <- function(data, index) {
   X <- data$medv[index]
   medvse = sd(X)/sqrt(length(X))
   return(medvse)
}
dim(Boston)
se.fn(Boston, 1:506)
```
The estimate of the standard error of μˆ is 0.4088611. This means that the sample mean of medv is 0.4088611 away from the population mean of medv.

(c) Now estimate the standard error of μˆ using the bootstrap. How does this compare to your answer from (b)?
```{r}
library(boot)
library(ISLR2)
set.seed(2)
boot.fn <- function(data, index) {
    m <- mean(data$medv[index])
    return (m)
}
boot(Boston, boot.fn, 1000)

```
The standard error of μˆ using the bootstrap is 0.407299. This is close to the standard error of μˆ obtained in (b), which is 0.4088611.


(d) Based on your bootstrap estimate from (c), provide a 95 % con- fidence interval for the mean of medv. Compare it to the results obtained using t.test(Boston$medv).
Hint: You can approximate a 95 % confidence interval using the formula [μˆ − 2SE(μˆ), μˆ + 2SE(μˆ)].
```{r}
t.test(Boston$medv)
CI.m <- c(22.53 - 2*0.407299, 22.53 + 2*0.407299)
CI.m
```
The 95% confidence interval for the mean of medv using the bootstrap is [21.7154, 23.3446]. The 95% confidence interval for the mean of medv using t.test(Boston$medv) is [21.72953, 23.33608]. The two confidence intervals are very close and the bond of bootstrap is little larger than t test.

(e) Based on this data set, provide an estimate, μˆmed, for the median value of medv in the population.
```{r}
median.fn <- function(data, index) {
   X <- data$medv[index]
   medvmedian = median(X)
   return(medvmedian)
}
dim(Boston)
median.fn(Boston, 1:506)
```
(f) Wenowwouldliketoestimatethestandarderrorofμˆmed.Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.
```{r}
set.seed(3)
boot.fn <- function(data, index) {
    m <- median(data$medv[index])
    return (m)
}
boot(Boston, boot.fn, 1000)
```
The standard error of μˆmed using the bootstrap is 0.3651739.  The median of medv is the same of e, which is 21.2.

(g) Based on this data set, provide an estimate for the tenth per- centile of medv in Boston census tracts. Call this quantity μˆ0.1. (You can use the quantile() function.)
```{r}
quantile(Boston$medv, 0.1)
```
The estimate for the tenth percentile of medv in Boston census tracts is 12.75.

(h) Use the bootstrap to estimate the standard error of μˆ0.1. Com- ment on your findings.
```{r}
set.seed(4)
boot.fn <- function(data, index) {
    q <- quantile(data$medv[index], 0.1)
    return (q)
}
boot(Boston, boot.fn, 1000)
```
The standard error of μˆ0.1 using the bootstrap is 0.504859. The tenth percentile of medv is 12.75, which is equal to g.


## Least squares is MLE (10pts)

Show that in the case of linear model with Gaussian errors, maximum likelihood and least squares are the same thing, and $C_p$ and AIC are equivalent.


## ISL Exercise 6.6.1 (10pts)
1. We perform best subset, forward stepwise, and backward stepwise selection on a single data set. For each approach, we obtain p + 1 models, containing 0, 1, 2, . . . , p predictors. Explain your answers:
(a) Which of the three models with k predictors has the smallest training RSS?

The best subset selection has the smallest training RSS because it considers all possible models with k predictors and selects the best one. Both forward and backward
selection determine models that depend on which predictors they pick first as they iterate
toward the kth model, meaning that a poor choice early on cannot be undone.

(b) Which of the three models with k predictors has the smallest test RSS?

The best subset selection has the smallest test RSS because it takes into account more models than the other methods

(c) True or False:
i. The predictors in the k-variable model identified by forward stepwise are a subset of the predictors in the (k+1)-variable model identified by forward stepwise selection.
ii. The predictors in the k-variable model identified by back- ward stepwise are a subset of the predictors in the (k + 1)- variable model identified by backward stepwise selection.
iii. The predictors in the k-variable model identified by back- ward stepwise are a subset of the predictors in the (k + 1)- variable model identified by forward stepwise selection.
iv. The predictors in the k-variable model identified by forward stepwise are a subset of the predictors in the (k+1)-variable model identified by backward stepwise selection.
v. The predictors in the k-variable model identified by best subset are a subset of the predictors in the (k + 1)-variable model identified by best subset selection.

i. True. 
Adding one additional predictor to the model with k predictors results in the model with (k+1) predictors.
ii. True, 
One predictor is removed from the model with (k+1) predictors to obtain the model with k predictors.
iii. False
The models obtained from forward and backward selection are not directly connected or interlinked.
iv. False
The models obtained from forward and backward selection are not directly connected or interlinked.
v. True
The model with (k+1) predictors is derived by choosing from a pool of all potential models with (k+1) predictors, meaning it may not include every predictor chosen for the k-variable model.
## ISL Exercise 6.6.3 (10pts)

## ISL Exercise 6.6.4 (10pts)

## ISL Exercise 6.6.5 (10pts)

## ISL Exercise 6.6.11 (30pts)

You must follow the [typical machine learning paradigm](https://ucla-econ-425t.github.io/2023winter/slides/06-modelselection/workflow_lasso.html) to compare _at least_ 3 methods: least squares, lasso, and ridge. Report final results as

| Method | CV RMSE | Test RMSE |
|:------:|:------:|:------:|:------:|
| LS | | | |
| Ridge | | | |
| Lasso | | | |
| ... | | | |

## Bonus question (20pts)

Consider a linear regression, fit by least squares to a set of training data $(x_1, y_1), \ldots, (x_N,  y_N)$ drawn at random from a population. Let $\hat \beta$ be the least squares estimate. Suppose we have some test data $(\tilde{x}_1, \tilde{y}_1), \ldots, (\tilde{x}_M, \tilde{y}_M)$ drawn at random from the same population as the training data. If $R_{\text{train}}(\beta) = \frac{1}{N} \sum_{i=1}^N (y_i - \beta^T x_i)^2$ and $R_{\text{test}}(\beta) = \frac{1}{M} \sum_{i=1}^M (\tilde{y}_i - \beta^T \tilde{x}_i)^2$. Show that
$$
\operatorname{E}[R_{\text{train}}(\hat{\beta})] < \operatorname{E}[R_{\text{test}}(\hat{\beta})].
$$